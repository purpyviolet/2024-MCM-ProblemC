{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改进势头计算函数以包括赢得的局数和盘数，以及更精确的发球优势计算\n",
    "def calculate_streak(df, index, window_size=4):\n",
    "    start_index = max(index - window_size, 0)\n",
    "    end_index = min(index + window_size + 1, len(df))\n",
    "    time_window_df = df.iloc[start_index:end_index]\n",
    "\n",
    "    # 初始化势头值\n",
    "    p1_streak = 0\n",
    "    p2_streak = 0\n",
    "\n",
    "    # 计算“连胜”值\n",
    "    p1_streak = time_window_df['game_victor'].apply(lambda x: 1 if x == 1 else 0).cumsum().max()\n",
    "    p2_streak = time_window_df['game_victor'].apply(lambda x: 1 if x == 2 else 0).cumsum().max()\n",
    "\n",
    "\n",
    "    return p1_streak, p2_streak\n",
    "\n",
    "\n",
    "# 对数据集中的每一行应用计算势头的函数\n",
    "# streak_values = [calculate_streak(match_data, index) for index in range(len(match_data))]\n",
    "\n",
    "# streak_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_physical_strength(df, index, window_size=3):\n",
    "    start_index = max(index - window_size, 0)\n",
    "    end_index = min(index + window_size + 1, len(df))\n",
    "    time_window_df = df.iloc[start_index:end_index]\n",
    "\n",
    "    # 初始化体力值\n",
    "    p1_physical_strength = 0\n",
    "    p2_physical_strength = 0\n",
    "\n",
    "    # 共同因素\n",
    "    rally_count = time_window_df['rally_count'].sum()\n",
    "    # 确定发球者是球员1还是球员2\n",
    "    serving_player = time_window_df['server'].iloc[-1]\n",
    "\n",
    "    # 根据发球者计算速度和跑动距离\n",
    "    if serving_player == 1:\n",
    "        p1_speed_mph = time_window_df['speed_mph'].iloc[-1]\n",
    "        p2_speed_mph = 0\n",
    "\n",
    "    else:\n",
    "        p2_speed_mph = time_window_df['speed_mph'].iloc[-1]\n",
    "        p1_speed_mph = 0\n",
    "        \n",
    "    \n",
    "    p1_distance_run = time_window_df['p1_distance_run'].iloc[-1]\n",
    "    p2_distance_run = time_window_df['p2_distance_run'].iloc[-1]\n",
    "    # 考虑速度和跑动距离对体力值的影响\n",
    "    p1_physical_strength += p1_speed_mph\n",
    "    p2_physical_strength += p2_speed_mph\n",
    "\n",
    "    p1_physical_strength += p1_distance_run\n",
    "    p2_physical_strength += p2_distance_run\n",
    "\n",
    "    # 考虑击球次数对体力值的影响\n",
    "    p1_physical_strength += rally_count\n",
    "    p2_physical_strength += rally_count\n",
    "\n",
    "    return p1_physical_strength, p2_physical_strength\n",
    "\n",
    "\n",
    "# physical_strength = [calculate_physical_strength(match_data, index) for index in range(len(match_data))]\n",
    "# physical_strength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_momentum_topsis(match_data, speed_weight=0.01):\n",
    "    # 复制数据以避免修改原始数据\n",
    "    match_data = match_data.copy()\n",
    "\n",
    "    # 创建新的列 score_difference\n",
    "    def map_score_to_number(score):\n",
    "        score_mapping = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4}\n",
    "        return score_mapping.get(score, 0)\n",
    "\n",
    "    # 应用映射函数到 p1_score 和 p2_score 列\n",
    "    match_data['p1_score_number'] = match_data['p1_score'].apply(map_score_to_number)\n",
    "    match_data['p2_score_number'] = match_data['p2_score'].apply(map_score_to_number)\n",
    "\n",
    "    # 计算得分差\n",
    "    match_data['score_difference'] = match_data['p1_score_number'] - match_data['p2_score_number']\n",
    "    match_data['game_difference'] = match_data['p1_games'] - match_data['p2_games']\n",
    "    match_data['set_difference'] = match_data['p1_sets'] - match_data['p2_sets']\n",
    "\n",
    "    # 选择进行Topsis分析的特征列\n",
    "    selected_features = ['p1_net_pt_won', 'p1_ace', 'score_difference', 'game_difference', 'set_difference', 'p1_winner', 'p1_double_fault', 'p1_unf_err', 'p1_break_pt_won', 'speed_mph']\n",
    "    selected_features += ['p2_net_pt_won','p2_ace', 'p2_winner', 'p2_double_fault', 'p2_unf_err', 'p2_break_pt_won']\n",
    "\n",
    "    # 使用均值填充speed\n",
    "    mean_speed = match_data['speed_mph'].mean()\n",
    "    match_data['speed_mph'].fillna(mean_speed, inplace=True)\n",
    "\n",
    "    # 提取这些特征列的数据\n",
    "    features_data = match_data[selected_features]\n",
    "\n",
    "    # 步骤1：数据标准化（使用 Min-Max 标准化）\n",
    "    scaler = MinMaxScaler()\n",
    "    normalized_data = scaler.fit_transform(features_data)\n",
    "\n",
    "    # 步骤2：计算每个指标的信息熵\n",
    "    entropy_values = -normalized_data * np.log2(normalized_data)\n",
    "    entropy_values[np.isnan(entropy_values)] = 0  # 处理NaN值\n",
    "    entropy_per_indicator = np.sum(entropy_values, axis=0)\n",
    "\n",
    "    # 步骤3：计算每个指标的权重\n",
    "    weights = 1 - (entropy_per_indicator / np.sum(entropy_per_indicator))\n",
    "\n",
    "    # 步骤4：计算加权标准化值\n",
    "    weighted_normalized_data = normalized_data * weights\n",
    "\n",
    "    # 步骤5：正向化负向指标\n",
    "    # 假设所有指标都是越大越好，后续再处理正负号\n",
    "\n",
    "    # 步骤6：计算正负理想解\n",
    "    positive_ideal_solution = weighted_normalized_data.max(axis=0)\n",
    "    negative_ideal_solution = weighted_normalized_data.min(axis=0)\n",
    "\n",
    "    # 步骤7：计算距离\n",
    "    distance_to_positive_ideal = np.linalg.norm(weighted_normalized_data - positive_ideal_solution, axis=1)\n",
    "    distance_to_negative_ideal = np.linalg.norm(weighted_normalized_data - negative_ideal_solution, axis=1)\n",
    "\n",
    "    # 步骤8：计算综合得分\n",
    "    composite_score = distance_to_negative_ideal / (distance_to_positive_ideal + distance_to_negative_ideal)\n",
    "\n",
    "    # 步骤2：使用比分差距进行势头计算\n",
    "    match_data['score_momentum'] = match_data['score_difference'] * composite_score\n",
    "\n",
    "    # 步骤3：将各项比分差异乘以 composite_score\n",
    "    match_data['game_momentum'] = match_data['game_difference'] * composite_score\n",
    "    match_data['set_momentum'] = match_data['set_difference'] * composite_score\n",
    "\n",
    "    # 步骤4：将所有势头指标结合计算动量\n",
    "    match_data['p1_momentum_topsis'] = -match_data['score_momentum'] + match_data['p1_net_pt_won'] + match_data['p1_ace'] - match_data['game_momentum'] - match_data['set_momentum']\n",
    "    match_data['p1_momentum_topsis'] += match_data['p1_winner'] - match_data['p1_double_fault'] - match_data['p1_unf_err'] + match_data['p1_break_pt_won'] + speed_weight * match_data['speed_mph']\n",
    "    match_data['p1_momentum_topsis'] += -match_data['p2_winner'] - match_data['p2_ace'] - match_data['p2_break_pt_won']\n",
    "    match_data['p2_momentum_topsis'] = match_data['score_momentum'] + match_data['p2_net_pt_won'] + match_data['p2_ace'] + match_data['game_momentum'] + match_data['set_momentum']\n",
    "    match_data['p2_momentum_topsis'] += match_data['p2_winner'] - match_data['p2_double_fault'] - match_data['p2_unf_err'] + match_data['p2_break_pt_won'] + speed_weight * match_data['speed_mph']\n",
    "    match_data['p2_momentum_topsis'] += -match_data['p1_winner'] - match_data['p1_ace'] - match_data['p1_break_pt_won']\n",
    "\n",
    "    return match_data['p1_momentum_topsis'], match_data['p2_momentum_topsis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 改进势头计算函数以包括赢得的局数和盘数，以及更精确的发球优势计算\n",
    "def calculate_momentum_improved(df, index, window_size=3):\n",
    "    start_index = max(index - window_size, 0)\n",
    "    end_index = min(index + window_size + 1, len(df))\n",
    "    time_window_df = df.iloc[start_index:end_index]\n",
    "\n",
    "    # 初始化势头值\n",
    "    p1_momentum = 0\n",
    "    p2_momentum = 0\n",
    "\n",
    "    # 赢得的局数和盘数\n",
    "    p1_sets_won = time_window_df['p1_sets'].iloc[-1] - time_window_df['p1_sets'].iloc[0]\n",
    "    p2_sets_won = time_window_df['p2_sets'].iloc[-1] - time_window_df['p2_sets'].iloc[0]\n",
    "    p1_games_won = time_window_df['p1_games'].iloc[-1] - time_window_df['p1_games'].iloc[0]\n",
    "    p2_games_won = time_window_df['p2_games'].iloc[-1] - time_window_df['p2_games'].iloc[0]\n",
    "\n",
    "    # 发球优势\n",
    "    # 假设发球方在每个得分上的额外权重为0.1\n",
    "    serve_advantage_weight = 0.1\n",
    "    p1_serve_advantage = (time_window_df[time_window_df['server'] == 1]['point_victor'] == 1).sum() * serve_advantage_weight\n",
    "    p2_serve_advantage = (time_window_df[time_window_df['server'] == 2]['point_victor'] == 2).sum() * serve_advantage_weight\n",
    "\n",
    "    # 其他因素（得分优势、破发点、非受迫性失误、制胜分）\n",
    "    p1_points_advantage = time_window_df['point_victor'].apply(lambda x: x == 1).sum() - time_window_df['point_victor'].apply(lambda x: x == 2).sum()\n",
    "    p2_points_advantage = -p1_points_advantage\n",
    "    p1_break_points_won = time_window_df['p1_break_pt_won'].sum()\n",
    "    p2_break_points_won = time_window_df['p2_break_pt_won'].sum()\n",
    "    p1_unforced_errors = -time_window_df['p1_unf_err'].sum()\n",
    "    p2_unforced_errors = -time_window_df['p2_unf_err'].sum()\n",
    "    p1_winners = time_window_df['p1_winner'].sum()\n",
    "    p2_winners = time_window_df['p2_winner'].sum()\n",
    "\n",
    "    # 合并计算势头\n",
    "    p1_momentum = p1_points_advantage + p1_serve_advantage + p1_break_points_won + p1_unforced_errors + p1_winners + p1_sets_won + p1_games_won\n",
    "    p2_momentum = p2_points_advantage + p2_serve_advantage + p2_break_points_won + p2_unforced_errors + p2_winners + p2_sets_won + p2_games_won\n",
    "\n",
    "    return p1_momentum, p2_momentum\n",
    "\n",
    "def cumsum_detection(series):\n",
    "    \"\"\"\n",
    "    CUMSUM检测算法实现，用于检测序列中的转折点。\n",
    "    :param series: 一维数据序列 (Pandas Series)\n",
    "    :return: 转折点的索引列表\n",
    "    \"\"\"\n",
    "    # 计算差分序列\n",
    "    diff_series = series.diff().fillna(0)  # 用0填充NaN值\n",
    "    \n",
    "    # 计算累积和\n",
    "    cumsum_series = diff_series.cumsum()\n",
    "    \n",
    "    # 识别转折点：当累积和重新穿过零点时，认为是一个转折点\n",
    "    turning_points = []\n",
    "    for i in range(1, len(cumsum_series)):\n",
    "        # 如果累积和的符号与前一个不同，则认为是转折点\n",
    "        if cumsum_series[i] * cumsum_series[i-1] < 0:\n",
    "            turning_points.append(i)\n",
    "    \n",
    "    return turning_points\n",
    "\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "def runs_test(sequence):\n",
    "    \"\"\"\n",
    "    游程检验，判断序列随机性。\n",
    "    :param sequence: 输入的序列 (list or np.array)\n",
    "    :return: Z统计量和p值\n",
    "    \"\"\"\n",
    "    # 将序列分为两类\n",
    "    median_value = np.median(sequence)\n",
    "    binary_sequence = [1 if x > median_value else 0 for x in sequence]\n",
    "    \n",
    "    # 计算游程数量\n",
    "    runs = 1  # 至少有一个游程\n",
    "    for i in range(1, len(binary_sequence)):\n",
    "        if binary_sequence[i] != binary_sequence[i-1]:\n",
    "            runs += 1\n",
    "    \n",
    "    # 计算期望的游程数量和标准差\n",
    "    n1 = binary_sequence.count(1)\n",
    "    n2 = binary_sequence.count(0)\n",
    "    expected_runs = 2 * n1 * n2 / (n1 + n2) + 1\n",
    "    variance = (expected_runs - 1) * (expected_runs - 2) / (n1 + n2 - 1)\n",
    "    \n",
    "    # 计算Z统计量\n",
    "    Z = (runs - expected_runs) / np.sqrt(variance)\n",
    "    \n",
    "    # 计算p值\n",
    "    p_value = 2 * (1 - norm.cdf(abs(Z)))  # 双尾检验\n",
    "    \n",
    "    return Z, p_value\n",
    "\n",
    "\n",
    "def mark_indices_in_list(length, indices):\n",
    "    \"\"\"\n",
    "    根据指定的索引列表，在长度为length的列表中标记索引位置。\n",
    "    \n",
    "    :param length: 列表的长度\n",
    "    :param indices: 需要标记为1的索引值列表\n",
    "    :return: 标记后的列表，其中指定索引位置为1，其他位置为0\n",
    "    \"\"\"\n",
    "    # 初始化列表，长度为length，所有值为0\n",
    "    marked_list = [0] * length\n",
    "    \n",
    "    # 在指定索引位置标记为1\n",
    "    for index in indices:\n",
    "        if index < length:  # 确保索引在列表长度范围内\n",
    "            marked_list[index] = 1\n",
    "            \n",
    "    return marked_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def getva(x):\n",
    "    # print(x)\n",
    "    if x<0.05:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "# 读取数据\n",
    "df = pd.read_csv('american_clean_data.csv')\n",
    "\n",
    "# 选择一场特定的比赛进行分析，根据题目描述选择2023年温布尔登决赛\n",
    "# 假设决赛的match_id为\"2023-wimbledon-1701\"\n",
    "match_id = \"2023-usopen-1107\"\n",
    "match_data = df[df['match_id'] == match_id].copy()\n",
    "match_data.reset_index(inplace=True,drop=True)\n",
    "\n",
    "# 选择一场特定的比赛进行分析，根据题目描述选择2023年温布尔登决赛\n",
    "# 假设决赛的match_id为\"2023-wimbledon-1701\"\n",
    "# 对数据集中的每一行应用计算势头的函数\n",
    "momentum_values = [calculate_momentum_improved(match_data, index) for index in range(len(match_data))]\n",
    "p1_momentum_sub=[]\n",
    "p2_momentum_sub=[]\n",
    "for i in momentum_values:\n",
    "    p1_momentum_sub.append(i[0])\n",
    "    p2_momentum_sub.append(i[1])\n",
    "\n",
    "# 将计算得到的势头值分配回原始数据集\n",
    "match_data['p1_momentum_sub']=pd.DataFrame(p1_momentum_sub)\n",
    "match_data['p2_momentum_sub']=pd.DataFrame(p2_momentum_sub)\n",
    "match_data['p1_momentum_topsis'], match_data['p2_momentum_topsis'] = calculate_momentum_topsis(match_data)\n",
    "# 设置 Topsis 方法的权重\n",
    "topsis_weight = 0.2\n",
    "# 将 Topsis 方法的结果加权合并到总势头中\n",
    "p1_momentum = (1 - topsis_weight) * match_data['p1_momentum_sub'] + topsis_weight * match_data['p1_momentum_topsis']\n",
    "p2_momentum = (1 - topsis_weight) * match_data['p2_momentum_sub'] + topsis_weight * match_data['p2_momentum_topsis']    \n",
    "    \n",
    "# 将计算得到的势头值分配回原始数据集\n",
    "match_data['p1_momentum']=pd.DataFrame(p1_momentum)\n",
    "match_data['p2_momentum']=pd.DataFrame(p2_momentum)\n",
    "\n",
    "# 对数据集中的每一行应用计算势头的函数\n",
    "streak_values = [calculate_streak(match_data, index) for index in range(len(match_data))]\n",
    "physical_strength = [calculate_physical_strength(match_data, index) for index in range(len(match_data))]\n",
    "\n",
    "p1_streak=[]\n",
    "p2_streak=[]\n",
    "for i in streak_values:\n",
    "    p1_streak.append(i[0])\n",
    "    p2_streak.append(i[1])\n",
    "\n",
    "\n",
    "p1_physical_strength=[]\n",
    "p2_physical_strength=[]\n",
    "for i in physical_strength:\n",
    "    p1_physical_strength.append(i[0])\n",
    "    p2_physical_strength.append(i[1])\n",
    "\n",
    "# 将计算得到的新分量分配回原始数据集\n",
    "match_data['p1_streak']=pd.DataFrame(p1_streak)\n",
    "match_data['p2_streak']=pd.DataFrame(p2_streak)\n",
    "\n",
    "# match_data['p1_physical_strength']=pd.DataFrame(p1_physical_strength)\n",
    "# match_data['p2_physical_strength']=pd.DataFrame(p2_physical_strength)\n",
    "\n",
    "\n",
    "\n",
    "# 指定输出文件的路径和文件名\n",
    "output_file_path = 'american_1107_match_swing.csv'\n",
    "\n",
    "# 将数据保存到CSV文件\n",
    "match_data.to_csv(output_file_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
